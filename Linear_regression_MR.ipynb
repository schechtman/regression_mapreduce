{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article : https://arxiv.org/pdf/1307.0048.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée du projet est d'implementer un algorithme mapreduce sur la régression linéaire pénalisée, quand $X \\in \\mathbb{R}^{n \\times p}$ avec $p << n$.\n",
    "\n",
    "Cela correspond à un type de problème ou le nombre de features $p$ (les caractéristiques d'un individu ou un produit) est assez petit et il est envisageable de les stocker en mémoire, alors que la taille du dataset $n$ et très grande et on voudrait faire du calcul distributé dessus\n",
    "\n",
    "L'idée de l'agorithme est alors d'exprimer la quantité à minimiser en fonction des matrices ou des vecteurs dont la dimension est une fonction de $p$ ($p\\times p$ ou $p$ en fait). Et calculer ces quantitées à partir de $X \\in \\mathbb{R}^{n \\times p}$ en faisant une reduction sur $n$ (qui est la taille de notre dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.linalg.special_matrices import toeplitz\n",
    "\n",
    "p = 10\n",
    "n = 100\n",
    "cov = toeplitz(0.5 ** np.arange(p))\n",
    "A = multivariate_normal(np.zeros(p), cov, 100)\n",
    "A_sc = sc.parallelize(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1\n",
    "\n",
    "En notant $X_c \\in \\mathbb{R}^{n \\times p }$ la matrice centrée réduite de $X$. On a que minimiser:\n",
    "$$||Y - \\alpha \\mathbb{1} - X \\beta||_2 + p_\\lambda(\\beta)$$\n",
    "\n",
    "Revient au même que minimiser:\n",
    "$$\\begin{align}\n",
    "||Y - \\hat{\\alpha} \\mathbb{1} - X_c \\hat{\\beta}||_2 + p_\\lambda(\\hat{\\beta})\n",
    "\\end{align}$$\n",
    "Avec le changement de variable:\n",
    "\n",
    "$$\\begin{align} \n",
    "\\hat{\\alpha}&= \\alpha + \\left(\\bar{X_1}, \\dots, \\bar{X_p}\\right) \\beta \\\\\n",
    "\\hat{\\beta} &= D \\beta\n",
    "\\end{align}\n",
    " $$\n",
    " \n",
    " avec D la matrice diagonale des déviations standards.\n",
    " \n",
    " \n",
    " Comme maintenant les variables sont centrées, la minimisation en $\\hat{\\alpha}$ donne $\\hat{\\alpha} = \\bar{Y}$, et:\n",
    " $$\\begin{align}\n",
    " \\hat{\\beta}^* &= \\arg\\min_{\\hat{\\beta}} ||Y - \\hat{\\alpha} \\mathbb{1} - X_c \\hat{\\beta}||_2 + p_\\lambda(\\hat{\\beta}) \\\\\n",
    "             &= \\arg\\min_{\\hat{\\beta}} ||(Y - \\hat{\\alpha} \\mathbb{1})||_2^2  + ||X_c \\hat{\\beta}||_2^2 - 2(Y - \\hat{\\alpha} \\mathbb{1})^T X_c \\hat{\\beta}  + p_\\lambda(\\hat{\\beta}) \\\\\n",
    "             &= \\arg\\min_{\\hat{\\beta}} ||X_c \\hat{\\beta}||_2^2 - 2(Y - \\hat{\\alpha} \\mathbb{1})^T X_c \\hat{\\beta}  + p_\\lambda(\\hat{\\beta}) \\\\\n",
    "             &= \\arg\\min_{\\hat{\\beta}} \\hat{\\beta}^TX_c^T X_c \\hat{\\beta} - 2Y^T X_c\\hat{\\beta}  + p_\\lambda(\\hat{\\beta})\n",
    " \\end{align}$$\n",
    " \n",
    " $X_c^TX_c, Y^TX_c$ sont une matrice de taille $p \\times p$ et un vecteur de taille $p$. On peut donc par hypothèse les stocker en mémoire et résoudre ce problème par une des méthodes d'optimisation classiques (coordinate descent par exemple).\n",
    " \n",
    " Les quantités qu'on doit calculer sont $X_c^TX_c$ qui est la matrice de correlation de $X$. $Y^TX_c$ et $(\\bar{X_1}, \\dots, \\bar{X_p})$ (pour faire le changement de variables inverse).\n",
    " \n",
    " # En fait pas sûr de mon truc car quand on fait du cross validation centrée sur k-1 partition  с'est pas pareil que de centrer sur tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d400f3a938b1>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d400f3a938b1>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    X = X.map(lambda row: (row[0], row[1][i] - means[i] for i in range(p)))\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def PenalizedLR_MR(Data, k, lambdas):\n",
    "    \"\"\"\n",
    "    Data: an RDD each rows of which is a tuple (x, y)\n",
    "    k: number of partitions for splitting\n",
    "    lambdas: list of lambdas to test on\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #calculate means, variance,  standardize X\n",
    "    def reduce_mean(row1, row2):\n",
    "        s1 = row1[0]\n",
    "        s2 = row2[0]\n",
    "        \n",
    "        return (s1 + s2, s1 / (s1 + s2) * row1[1] + s2 / (s1 + s2) * row2[1])\n",
    "    \n",
    "    #vector of means of length p    \n",
    "    means_X = np.array(Data.map(lambda row: (1, row[0])).reduce(reduce_mean).collect()) \n",
    "    mean_Y = Data.map(lambda row: (1, row[1])).reduce(reduce_mean)\n",
    "    \n",
    "    p = len(means_X)\n",
    "    \n",
    "    #center X\n",
    "    Data.map(lambda row: (np.arrray([row[0][i] - means_X[i] for i in range(p)]), row[1]))\n",
    "    \n",
    "    # vector of variance of X of length p (using the fact that now X is centered)\n",
    "    vars_X = np.array(Data.map(lambda row: (1, row[0]**2)).reduce(reduce_mean).collect())\n",
    "    \n",
    "    #standardize X\n",
    "    Data.map(lambda row: (np.array([row[1][i] / vars_X[i] for i in range(p)]), row[1]))\n",
    "    \n",
    "        \n",
    "    def map_statistics(row):\n",
    "        # calculate statistics for one row [size, mean(x), mean(y), Y^TY, y * x, cov(x)]\n",
    "        return (np.random.randint(k), [1, x, y, y**2, y * x, np.zeros((len(row), len(row)))])\n",
    "\n",
    "    statistics = Data.map(map_statistics)\n",
    "\n",
    "    def reduce_statistics(row1, row2):\n",
    "        s_1 = row1[0]\n",
    "        s_2 = row2[0]\n",
    "        mean_x = s_1 / (s_1 + s_2) * row1[1] + s_2 / (s_1 + s_2) * row2[1]\n",
    "        mean_y = s_1 / (s_1 + s_2) * row1[2] + s_2 / (s_1 + s_2) * row2[2]\n",
    "        cov = s_1 / (s_1 + s_2) * row1[5] + s_2 / (s_1 + s_2) * row2[5] + s_1 * s_2 / (\n",
    "            s_1 + s_2)**2 * (row1[1] - row2[1]).T.dot(row1[1] - row2[1])\n",
    "        emit = [s_1 + s_2, mean_x, mean_y, row1[3] +\n",
    "                row2[3], row1[4] + row2[4], cov]\n",
    "        return emit\n",
    "\n",
    "    statistics = statistics.reduceByKey(reduce_statistics)\n",
    "\n",
    "    # Cross validation\n",
    "    if False:\n",
    "        for i in range(k):\n",
    "            statistics_train = statistics.filter(lambda row: row[0] != i)\n",
    "            statistics_train = statistics_train.reduce(reduce_statistics)\n",
    "            statistics_test = statistics.filter(lambda row: row[0] == i)\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1]), 1), (array([2]), 2), (array([3]), 3), (array([4]), 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = sc.parallelize([(np.array([i]), i) for i in range(1, 10)])\n",
    "test_data.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [9, array([[5.]]), 5.0, 285, array([[285]]), array([[6.66666667]])])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = PenalizedLR_MR(test_data, 1, [1])\n",
    "stat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.66666667)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(np.arange(1,10), bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
